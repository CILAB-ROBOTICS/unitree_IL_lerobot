Resolving data files: 100%|████████████████████████████████████████████████████████████████████████████████| 51/51 [00:00<00:00, 151601.35it/s]
Resolving data files: 100%|█████████████████████████████████████████████████████████████████████████████████| 20/20 [00:00<00:00, 16620.98it/s]
{'observation.state': {'dtype': 'float32', 'shape': (26,), 'names': [['kLeftShoulderPitch', 'kLeftShoulderRoll', 'kLeftShoulderYaw', 'kLeftElbow', 'kLeftWristRoll', 'kLeftWristPitch', 'kLeftWristYaw', 'kLeftHandPinky', 'kLeftHandRing', 'kLeftHandMiddle', 'kLeftHandIndex', 'kLeftHandThumbBend', 'kLeftHandThumbRotation', 'kRightShoulderPitch', 'kRightShoulderRoll', 'kRightShoulderYaw', 'kRightElbow', 'kRightWristRoll', 'kRightWristPitch', 'kRightWristYaw', 'kRightHandPinky', 'kRightHandRing', 'kRightHandMiddle', 'kRightHandIndex', 'kRightHandThumbBend', 'kRightHandThumbRotation']]}, 'action': {'dtype': 'float32', 'shape': (26,), 'names': [['kLeftShoulderPitch', 'kLeftShoulderRoll', 'kLeftShoulderYaw', 'kLeftElbow', 'kLeftWristRoll', 'kLeftWristPitch', 'kLeftWristYaw', 'kLeftHandPinky', 'kLeftHandRing', 'kLeftHandMiddle', 'kLeftHandIndex', 'kLeftHandThumbBend', 'kLeftHandThumbRotation', 'kRightShoulderPitch', 'kRightShoulderRoll', 'kRightShoulderYaw', 'kRightElbow', 'kRightWristRoll', 'kRightWristPitch', 'kRightWristYaw', 'kRightHandPinky', 'kRightHandRing', 'kRightHandMiddle', 'kRightHandIndex', 'kRightHandThumbBend', 'kRightHandThumbRotation']]}, 'observation.images.cam_left_high': {'dtype': 'video', 'shape': (3, 480, 848), 'names': ['channels', 'height', 'width'], 'info': {'video.fps': 30.0, 'video.height': 480, 'video.width': 848, 'video.channels': 3, 'video.codec': 'av1', 'video.pix_fmt': 'yuv420p', 'video.is_depth_map': False, 'has_audio': False}}, 'observation.images.cam_third': {'dtype': 'video', 'shape': (3, 480, 640), 'names': ['channels', 'height', 'width'], 'info': {'video.fps': 30.0, 'video.height': 480, 'video.width': 640, 'video.channels': 3, 'video.codec': 'av1', 'video.pix_fmt': 'yuv420p', 'video.is_depth_map': False, 'has_audio': False}}, 'observation.images.left_tactile_little_finger_tip': {'dtype': 'image', 'shape': (3, 3, 3), 'names': ['channels', 'height', 'width', 'channel']}, 'observation.images.left_tactile_little_finger_nail': {'dtype': 'image', 'shape': (3, 12, 8), 'names': ['channels', 'height', 'width', 'channel']}, 'observation.images.left_tactile_little_finger_pad': {'dtype': 'image', 'shape': (3, 10, 8), 'names': ['channels', 'height', 'width', 'channel']}, 'observation.images.left_tactile_ring_finger_tip': {'dtype': 'image', 'shape': (3, 3, 3), 'names': ['channels', 'height', 'width', 'channel']}, 'observation.images.left_tactile_ring_finger_nail': {'dtype': 'image', 'shape': (3, 12, 8), 'names': ['channels', 'height', 'width', 'channel']}, 'observation.images.left_tactile_ring_finger_pad': {'dtype': 'image', 'shape': (3, 10, 8), 'names': ['channels', 'height', 'width', 'channel']}, 'observation.images.left_tactile_middle_finger_tip': {'dtype': 'image', 'shape': (3, 3, 3), 'names': ['channels', 'height', 'width', 'channel']}, 'observation.images.left_tactile_middle_finger_nail': {'dtype': 'image', 'shape': (3, 12, 8), 'names': ['channels', 'height', 'width', 'channel']}, 'observation.images.left_tactile_middle_finger_pad': {'dtype': 'image', 'shape': (3, 10, 8), 'names': ['channels', 'height', 'width', 'channel']}, 'observation.images.left_tactile_index_finger_tip': {'dtype': 'image', 'shape': (3, 3, 3), 'names': ['channels', 'height', 'width', 'channel']}, 'observation.images.left_tactile_index_finger_nail': {'dtype': 'image', 'shape': (3, 12, 8), 'names': ['channels', 'height', 'width', 'channel']}, 'observation.images.left_tactile_index_finger_pad': {'dtype': 'image', 'shape': (3, 10, 8), 'names': ['channels', 'height', 'width', 'channel']}, 'observation.images.left_tactile_thumb_tip': {'dtype': 'image', 'shape': (3, 3, 3), 'names': ['channels', 'height', 'width', 'channel']}, 'observation.images.left_tactile_thumb_nail': {'dtype': 'image', 'shape': (3, 12, 8), 'names': ['channels', 'height', 'width', 'channel']}, 'observation.images.left_tactile_thumb_middle': {'dtype': 'image', 'shape': (3, 3, 3), 'names': ['channels', 'height', 'width', 'channel']}, 'observation.images.left_tactile_thumb_pad': {'dtype': 'image', 'shape': (3, 12, 8), 'names': ['channels', 'height', 'width', 'channel']},
{'observation.state': {'dtype': 'float32', 'shape': (26,), 'names': [['kLeftShoulderPitch', 'kLeftShoulderRoll', 'kLeftShoulderYaw', 'kLeftElbow', 'kLeftWristRoll', 'kLeftWristPitch', 'kLeftWristYaw', 'kLeftHandPinky', 'kLeftHandRing', 'kLeftHandMiddle', 'kLeftHandIndex', 'kLeftHandThumbBend', 'kLeftHandThumbRotation', 'kRightShoulderPitch', 'kRightShoulderRoll', 'kRightShoulderYaw', 'kRightElbow', 'kRightWristRoll', 'kRightWristPitch', 'kRightWristYaw', 'kRightHandPinky', 'kRightHandRing', 'kRightHandMiddle', 'kRightHandIndex', 'kRightHandThumbBend', 'kRightHandThumbRotation']]}, 'action': {'dtype': 'float32', 'shape': (26,), 'names': [['kLeftShoulderPitch', 'kLeftShoulderRoll', 'kLeftShoulderYaw', 'kLeftElbow', 'kLeftWristRoll', 'kLeftWristPitch', 'kLeftWristYaw', 'kLeftHandPinky', 'kLeftHandRing', 'kLeftHandMiddle', 'kLeftHandIndex', 'kLeftHandThumbBend', 'kLeftHandThumbRotation', 'kRightShoulderPitch', 'kRightShoulderRoll', 'kRightShoulderYaw', 'kRightElbow', 'kRightWristRoll', 'kRightWristPitch', 'kRightWristYaw', 'kRightHandPinky', 'kRightHandRing', 'kRightHandMiddle', 'kRightHandIndex', 'kRightHandThumbBend', 'kRightHandThumbRotation']]}, 'observation.images.cam_left_high': {'dtype': 'video', 'shape': (3, 480, 848), 'names': ['channels', 'height', 'width'], 'info': {'video.fps': 30.0, 'video.height': 480, 'video.width': 848, 'video.channels': 3, 'video.codec': 'av1', 'video.pix_fmt': 'yuv420p', 'video.is_depth_map': False, 'has_audio': False}}, 'observation.images.cam_third': {'dtype': 'video', 'shape': (3, 480, 640), 'names': ['channels', 'height', 'width'], 'info': {'video.fps': 30.0, 'video.height': 480, 'video.width': 640, 'video.channels': 3, 'video.codec': 'av1', 'video.pix_fmt': 'yuv420p', 'video.is_depth_map': False, 'has_audio': False}}, 'observation.images.left_tactile_little_finger_tip': {'dtype': 'image', 'shape': (3, 3, 3), 'names': ['channels', 'height', 'width', 'channel']}, 'observation.images.left_tactile_little_finger_nail': {'dtype': 'image', 'shape': (3, 12, 8), 'names': ['channels', 'height', 'width', 'channel']}, 'observation.images.left_tactile_little_finger_pad': {'dtype': 'image', 'shape': (3, 10, 8), 'names': ['channels', 'height', 'width', 'channel']}, 'observation.images.left_tactile_ring_finger_tip': {'dtype': 'image', 'shape': (3, 3, 3), 'names': ['channels', 'height', 'width', 'channel']}, 'observation.images.left_tactile_ring_finger_nail': {'dtype': 'image', 'shape': (3, 12, 8), 'names': ['channels', 'height', 'width', 'channel']}, 'observation.images.left_tactile_ring_finger_pad': {'dtype': 'image', 'shape': (3, 10, 8), 'names': ['channels', 'height', 'width', 'channel']}, 'observation.images.left_tactile_middle_finger_tip': {'dtype': 'image', 'shape': (3, 3, 3), 'names': ['channels', 'height', 'width', 'channel']}, 'observation.images.left_tactile_middle_finger_nail': {'dtype': 'image', 'shape': (3, 12, 8), 'names': ['channels', 'height', 'width', 'channel']}, 'observation.images.left_tactile_middle_finger_pad': {'dtype': 'image', 'shape': (3, 10, 8), 'names': ['channels', 'height', 'width', 'channel']}, 'observation.images.left_tactile_index_finger_tip': {'dtype': 'image', 'shape': (3, 3, 3), 'names': ['channels', 'height', 'width', 'channel']}, 'observation.images.left_tactile_index_finger_nail': {'dtype': 'image', 'shape': (3, 12, 8), 'names': ['channels', 'height', 'width', 'channel']}, 'observation.images.left_tactile_index_finger_pad': {'dtype': 'image', 'shape': (3, 10, 8), 'names': ['channels', 'height', 'width', 'channel']}, 'observation.images.left_tactile_thumb_tip': {'dtype': 'image', 'shape': (3, 3, 3), 'names': ['channels', 'height', 'width', 'channel']}, 'observation.images.left_tactile_thumb_nail': {'dtype': 'image', 'shape': (3, 12, 8), 'names': ['channels', 'height', 'width', 'channel']}, 'observation.images.left_tactile_thumb_middle': {'dtype': 'image', 'shape': (3, 3, 3), 'names': ['channels', 'height', 'width', 'channel']}, 'observation.images.left_tactile_thumb_pad': {'dtype': 'image', 'shape': (3, 12, 8), 'names': ['channels', 'height', 'width', 'channel']},
  0%|                                                                                                                  | 0/100 [00:20<?, ?it/s]
Traceback (most recent call last):
  File "/workspace/cilab_unitree_lerobot/lerobot/lerobot/scripts/pretrain.py", line 658, in <module>
    run_clip_pretraining(args)
  File "/workspace/cilab_unitree_lerobot/lerobot/lerobot/scripts/pretrain.py", line 621, in run_clip_pretraining
    clip_pretraining(train_dataset, test_dataset, train_features, save_dir=save_run_dir, args=args)
  File "/workspace/cilab_unitree_lerobot/lerobot/lerobot/scripts/pretrain.py", line 237, in clip_pretraining
    for batch_idx, batch in enumerate(train_loader):
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py", line 732, in __next__
    data = self._next_data()
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py", line 788, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py", line 52, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py", line 52, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/workspace/unitree_lerobot/lerobot/lerobot/common/datasets/lerobot_dataset.py", line 739, in __getitem__
    video_frames = self._query_videos(query_timestamps, ep_idx)
  File "/workspace/unitree_lerobot/lerobot/lerobot/common/datasets/lerobot_dataset.py", line 711, in _query_videos
    frames = decode_video_frames(video_path, query_ts, self.tolerance_s, self.video_backend)
  File "/workspace/unitree_lerobot/lerobot/lerobot/common/datasets/video_utils.py", line 66, in decode_video_frames
    return decode_video_frames_torchcodec(video_path, timestamps, tolerance_s)
  File "/workspace/unitree_lerobot/lerobot/lerobot/common/datasets/video_utils.py", line 195, in decode_video_frames_torchcodec
    decoder = VideoDecoder(video_path, device=device, seek_mode="approximate")
  File "/usr/local/lib/python3.10/dist-packages/torchcodec/decoders/_video_decoder.py", line 134, in __init__
    self._decoder = create_decoder(source=source, seek_mode=seek_mode)
  File "/usr/local/lib/python3.10/dist-packages/torchcodec/decoders/_decoder_utils.py", line 31, in create_decoder
    return core.create_from_file(str(source), seek_mode)
  File "/usr/local/lib/python3.10/dist-packages/torch/_ops.py", line 841, in __call__
    return self._op(*args, **kwargs)
KeyboardInterrupt
Traceback (most recent call last):
  File "/workspace/cilab_unitree_lerobot/lerobot/lerobot/scripts/pretrain.py", line 658, in <module>
    run_clip_pretraining(args)
  File "/workspace/cilab_unitree_lerobot/lerobot/lerobot/scripts/pretrain.py", line 621, in run_clip_pretraining
    clip_pretraining(train_dataset, test_dataset, train_features, save_dir=save_run_dir, args=args)
  File "/workspace/cilab_unitree_lerobot/lerobot/lerobot/scripts/pretrain.py", line 237, in clip_pretraining
    for batch_idx, batch in enumerate(train_loader):
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py", line 732, in __next__
    data = self._next_data()
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py", line 788, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py", line 52, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py", line 52, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/workspace/unitree_lerobot/lerobot/lerobot/common/datasets/lerobot_dataset.py", line 739, in __getitem__
    video_frames = self._query_videos(query_timestamps, ep_idx)
  File "/workspace/unitree_lerobot/lerobot/lerobot/common/datasets/lerobot_dataset.py", line 711, in _query_videos
    frames = decode_video_frames(video_path, query_ts, self.tolerance_s, self.video_backend)
  File "/workspace/unitree_lerobot/lerobot/lerobot/common/datasets/video_utils.py", line 66, in decode_video_frames
    return decode_video_frames_torchcodec(video_path, timestamps, tolerance_s)
  File "/workspace/unitree_lerobot/lerobot/lerobot/common/datasets/video_utils.py", line 195, in decode_video_frames_torchcodec
    decoder = VideoDecoder(video_path, device=device, seek_mode="approximate")
  File "/usr/local/lib/python3.10/dist-packages/torchcodec/decoders/_video_decoder.py", line 134, in __init__
    self._decoder = create_decoder(source=source, seek_mode=seek_mode)
  File "/usr/local/lib/python3.10/dist-packages/torchcodec/decoders/_decoder_utils.py", line 31, in create_decoder
    return core.create_from_file(str(source), seek_mode)
  File "/usr/local/lib/python3.10/dist-packages/torch/_ops.py", line 841, in __call__
    return self._op(*args, **kwargs)
KeyboardInterrupt
