Resolving data files: 100%|██████████████████████████████████████████████████████████████████████| 51/51 [00:00<00:00, 62619.88it/s]
Resolving data files: 100%|██████████████████████████████████████████████████████████████████████| 41/41 [00:00<00:00, 60679.77it/s]
Resolving data files: 100%|██████████████████████████████████████████████████████████████████████| 20/20 [00:00<00:00, 25653.24it/s]
  0%|                                                                                                       | 0/100 [00:00<?, ?it/s]WARNING 2025-11-24 07:06:57 /pretrain.py:51 Requested top-10 but batch size is 8. Using top-8 instead.
WARNING 2025-11-24 07:11:55 /pretrain.py:51 Requested top-5 but batch size is 1. Using top-1 instead.
WARNING 2025-11-24 07:11:55 /pretrain.py:51 Requested top-10 but batch size is 1. Using top-1 instead.
  1%|▉                                                                                         | 1/100 [21:31<35:31:22, 1291.74s/it]
Traceback (most recent call last):
  File "/workspace/cilab_unitree_lerobot/lerobot/lerobot/scripts/pretrain.py", line 655, in <module>
    parser.add_argument('--wandb_name', type=str, default='test', help='WandB run name')
  File "/workspace/cilab_unitree_lerobot/lerobot/lerobot/scripts/pretrain.py", line 618, in run_clip_pretraining
    f.write(f'test_dataset: {test_dataset}\n')
  File "/workspace/cilab_unitree_lerobot/lerobot/lerobot/scripts/pretrain.py", line 237, in clip_pretraining
    for batch_idx, batch in enumerate(train_loader):
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py", line 732, in __next__
    data = self._next_data()
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py", line 788, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py", line 52, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py", line 52, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataset.py", line 346, in __getitem__
    return self.datasets[dataset_idx][sample_idx]
  File "/workspace/unitree_lerobot/lerobot/lerobot/common/datasets/lerobot_dataset.py", line 739, in __getitem__
    video_frames = self._query_videos(query_timestamps, ep_idx)
  File "/workspace/unitree_lerobot/lerobot/lerobot/common/datasets/lerobot_dataset.py", line 711, in _query_videos
    frames = decode_video_frames(video_path, query_ts, self.tolerance_s, self.video_backend)
  File "/workspace/unitree_lerobot/lerobot/lerobot/common/datasets/video_utils.py", line 66, in decode_video_frames
    return decode_video_frames_torchcodec(video_path, timestamps, tolerance_s)
  File "/workspace/unitree_lerobot/lerobot/lerobot/common/datasets/video_utils.py", line 206, in decode_video_frames_torchcodec
    frames_batch = decoder.get_frames_at(indices=frame_indices)
  File "/usr/local/lib/python3.10/dist-packages/torchcodec/decoders/_video_decoder.py", line 259, in get_frames_at
    data, pts_seconds, duration_seconds = core.get_frames_at_indices(
  File "/usr/local/lib/python3.10/dist-packages/torchcodec/_core/ops.py", line 246, in get_frames_at_indices
    return _get_frames_at_indices_tensor_input(decoder, frame_indices=frame_indices)
  File "/usr/local/lib/python3.10/dist-packages/torch/_ops.py", line 841, in __call__
    return self._op(*args, **kwargs)
KeyboardInterrupt
Traceback (most recent call last):
  File "/workspace/cilab_unitree_lerobot/lerobot/lerobot/scripts/pretrain.py", line 655, in <module>
    parser.add_argument('--wandb_name', type=str, default='test', help='WandB run name')
  File "/workspace/cilab_unitree_lerobot/lerobot/lerobot/scripts/pretrain.py", line 618, in run_clip_pretraining
    f.write(f'test_dataset: {test_dataset}\n')
  File "/workspace/cilab_unitree_lerobot/lerobot/lerobot/scripts/pretrain.py", line 237, in clip_pretraining
    for batch_idx, batch in enumerate(train_loader):
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py", line 732, in __next__
    data = self._next_data()
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py", line 788, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py", line 52, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py", line 52, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataset.py", line 346, in __getitem__
    return self.datasets[dataset_idx][sample_idx]
  File "/workspace/unitree_lerobot/lerobot/lerobot/common/datasets/lerobot_dataset.py", line 739, in __getitem__
    video_frames = self._query_videos(query_timestamps, ep_idx)
  File "/workspace/unitree_lerobot/lerobot/lerobot/common/datasets/lerobot_dataset.py", line 711, in _query_videos
    frames = decode_video_frames(video_path, query_ts, self.tolerance_s, self.video_backend)
  File "/workspace/unitree_lerobot/lerobot/lerobot/common/datasets/video_utils.py", line 66, in decode_video_frames
    return decode_video_frames_torchcodec(video_path, timestamps, tolerance_s)
  File "/workspace/unitree_lerobot/lerobot/lerobot/common/datasets/video_utils.py", line 206, in decode_video_frames_torchcodec
    frames_batch = decoder.get_frames_at(indices=frame_indices)
  File "/usr/local/lib/python3.10/dist-packages/torchcodec/decoders/_video_decoder.py", line 259, in get_frames_at
    data, pts_seconds, duration_seconds = core.get_frames_at_indices(
  File "/usr/local/lib/python3.10/dist-packages/torchcodec/_core/ops.py", line 246, in get_frames_at_indices
    return _get_frames_at_indices_tensor_input(decoder, frame_indices=frame_indices)
  File "/usr/local/lib/python3.10/dist-packages/torch/_ops.py", line 841, in __call__
    return self._op(*args, **kwargs)
KeyboardInterrupt
